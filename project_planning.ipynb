{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a high-level guideline for a handwriting recognition project using OpenCV and PyTorch:\n",
    "\n",
    "1. **Data Collection and Preprocessing**:\n",
    "   - Collect a dataset of handwriting images. We can use existing datasets like the [IAM Handwriting Database](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database) (which we must download manually from Handwriting Database. There is one downside, we must sign-up to download it, after downloading this [Dataset](data/sentences.tgz), zip it in Datasets/IAM_Sentences folder. Also, we will need to download [annotations](data/ascii.tgz) and zip it to the exact location.)or collect by our own.\n",
    "   - Preprocess the images using OpenCV. This might include converting to grayscale, resizing, applying filters to remove noise, and thresholding to make the images binary.\n",
    "\n",
    "2. **Data Augmentation**:\n",
    "   - To increase the robustness of our model, we can augment the dataset by applying transformations like rotation, scaling, translation, etc.\n",
    "\n",
    "3. **Feature Extraction**:\n",
    "   - Extract features from the preprocessed images. This could be done using traditional methods like HOG (Histogram of Oriented Gradients), or we can use a Convolutional Neural Network (CNN) in PyTorch to learn features directly from the data.\n",
    "\n",
    "4. **Model Training**:\n",
    "   - Train a model on our features using PyTorch. This could be a simple feed-forward neural network, or something more complex like a CNN or a Recurrent Neural Network (RNN) if we need to deal with sequences of characters.\n",
    "\n",
    "5. **Model Evaluation and Optimization**:\n",
    "   - Evaluate the model's performance and optimize it as necessary. This might involve tuning hyperparameters, changing the model architecture, or collecting more data.\n",
    "\n",
    "6. **Deployment**:\n",
    "   - Once the model is trained and optimized, we'll need to deploy it. This could involve integrating it into an application, setting it up on a server, etc.\n",
    "\n",
    "We can divide the work among groupmates based on these parts. For example, one person could handle data collection and preprocessing, another could work on feature extraction, another on model training, and so on. It's a good idea to have everyone involved in the evaluation and optimization process, as this often requires a lot of trial and error and benefits from multiple perspectives.\n",
    "\n",
    "We will try to use opencv instead of torchvision whenever it is possible, since it is teached in the ailab course, and pytorch also provides conversions from numpy array(used in opencv) to torch.tensor(used by pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRNN\n",
    "For recognizing handwritten text from an image, a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) is often used. This combination is known as a CRNN (Convolutional Recurrent Neural Network).\n",
    "\n",
    "Here's a brief explanation of how it works:\n",
    "\n",
    "1. **Convolutional Neural Networks (CNNs)**: The initial layers of the network are typically convolutional. These layers are responsible for learning local features of the image. They can recognize patterns like lines, curves which are then combined to form more complex patterns.\n",
    "\n",
    "2. **Recurrent Neural Networks (RNNs)**: The features learned by the CNN are then passed to a RNN. RNNs are designed to work with sequence data. Since text is a sequence of characters, RNNs can use the patterns recognized by the CNN to understand the sequence of characters in the image.\n",
    "\n",
    "3. **Connectionist Temporal Classification (CTC)**: Finally, a CTC layer is used to convert the sequence predictions made by the RNN into actual readable text. CTC can handle the alignment between the predicted sequences and the target sequences, which is especially useful when dealing with handwriting, as the length of the written text can vary a lot.\n",
    "\n",
    "This combination allows the network to not only recognize individual characters in the image, but also understand the sequence in which they appear, which is crucial for text recognition.\n",
    "\n",
    "In terms of implementation, PyTorch provides all the necessary components to build such a network. There are also many tutorials and open-source projects available online that you can use as a starting point.\n",
    "\n",
    "### Reference\n",
    "I have found tutorials that use Tensorflow and mltu package(written by the author of the project himself, we will try to not use it and implement needed functions by ourself) to achieve sentence recognition at this [link](https://pylessons.com/handwritten-sentence-recognition) and the corresponding [github repository](https://github.com/pythonlessons/mltu/blob/main/Tutorials/04_sentence_recognition/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Here are some popular open-source projects for handwritten text recognition using CRNN:**\n",
    "\n",
    "1. [SimpleHTR](https://github.com/githubharald/SimpleHTR): This is a HTR (Handwritten Text Recognition) system implemented with TensorFlow. The implementation uses a CRNN composed of 7 layers: 2 CNN, 2 RNN and a CTC layer.\n",
    "\n",
    "2. [CRNN for Chinese Characters Recognition](https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec): This project is a CRNN implementation for Chinese characters recognition, but it can be easily adapted for other languages.\n",
    "\n",
    "3. [CRNN with PyTorch](https://github.com/meijieru/crnn.pytorch): This is an implementation of CRNN in PyTorch. It's a simple and clean implementation that's easy to understand and modify.\n",
    "\n",
    "4. [Handwriting Recognition System](https://github.com/ThomasDelteil/HandwrittenTextRecognition_MXNet): This project uses a combination of CNN, RNN (LSTM), and CTC loss to build a handwriting recognition system. It's implemented using Apache MXNet, but the concepts can be applied in PyTorch as well.\n",
    "\n",
    "Remember to respect the licenses of these projects if you decide to use or adapt them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard \n",
    "We will use the tensorboard package to visualize the loss functions (CTC loss CER loss),  install it inside the environment where you have opencv and pytorch installed with:  **conda install tensorboard**\n",
    "then the training logs will be saved by default in 'runs' directory, to visualize it type in anaconda prompt: tensorboard ---logdir=runs\n",
    "here is an example, run the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "y = -5 * x + 0.1 * torch.randn(x.size())\n",
    "\n",
    "model = torch.nn.Linear(1, 1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "def train_model(iter):\n",
    "    for epoch in range(iter):\n",
    "        y1 = model(x)\n",
    "        loss = criterion(y1, y)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train_model(10)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run **tensorboard --logdir=runs** in anaconda terminal and open http://localhost:6006/ in the browser to see the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir runs (started 0:01:16 ago; pid 35380)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b2fe57401f29ad75\" width=\"100%\" height=\"10\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b2fe57401f29ad75\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to visualize it in the notebook\n",
    "notebook.display(port=6006, height=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Assignment\n",
    "1. Data loading and preprocessing: (like normalization, resizing, augumentation and denoising etc.), and setting up data loaders for training and validation. <br>\n",
    ">Tools needed: Dataset and Dataloader from torch.utils.data, opencv, iam-handwriting-dataset\n",
    "\n",
    "2.  Model training and Neural Network architecture: This involves designing the neural network architecture, setting up the training loop, implementing the appropriate loss function, and training the model. <br>\n",
    ">Tools needed: PyTorch, CUDA (if available).\n",
    "\n",
    "3. Model Evaluation and result visualization: This involves evaluating the model on a validation set, analyzing the loss function, and visualizing the results. <br>\n",
    ">Tools needed: tensorboard,  matplotlib\n",
    "\n",
    "4. Model Deployment and Graphical User Interface design: deploying the model in a suitable environment, and designing a graphical user interface for interacting with the model. <br>\n",
    ">Possible tools:Suitable GUI library (like Tkinter, PyQt, etc.), Flask/Django (for web deployment), PyTorch \n",
    "\n",
    "<br>\n",
    "Regarding the documentation, each of us will provide his/her own part and we will merge it together in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
